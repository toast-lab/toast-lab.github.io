<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Lab 12 - Computer Architecture I - ShanghaiTech University</title>
<link rel="shortcut icon" type="image/png" href="../../favicon.ico">

<style type="text/css">
code {background-color: #ddeeff; color: #000000;}
kbd {background-color: #ddeeff; color: #000000;}
.new {background-color: #ffff00; color: #000000;}

.checkoff {
  background:#eeeee0;
  padding:0.5em 1.5em 0.5em 1.5em;
  border-radius:1em;
  border:1px solid #ddd;
}

pre {
  background:#adc384;
  padding:0.5em 1.5em 0.5em 1.5em;
  border:1px solid #ddd;
}


</style>
<link rel="stylesheet" type="text/css" href="../style.css">

</head>
<body>
<header>
<h2>Lab 12</h2>
</header>
<a href="../../">Computer Architecture I</a> <a href="http://www.shanghaitech.edu.cn">ShanghaiTech University</a><br>
<a href="../11">Lab 11</a> Lab 12 <a href="../13">Lab 13</a>

<h2>Objectives:</h2>
<ul>
  <li>Get hands-on experience running MapReduce and gain a deeper understanding of the MapReduce paradigm.</li>
  <li>Become more familiar with Apache Spark and get hands on experience with running Spark on a local installation.</li>
  <li>Learn how to apply the MapReduce paradigm to Spark by implementing certain problems/algorithms in Spark.</li>
</ul>

<h2>Setup</h2>
<p>Please follow the guide in <a href="https://autolab.sist.shanghaitech.edu.cn/gitlab/cs110/lab-12-starter">starter file</a> to setup the environment. Also, please pull the files from the repository.</p>

<p><strong>NOTE:</strong> some files are managed by Git LFS, make sure you have pulled the correct files.</p>

<h2 id="exercise">Exercises</h2>

<h3 id="exercise-1">Exercise 1</h3>

<p>Please finish the environment setup, exercise 0, and exercise 1 in the guide.</p>

<div class="checkoff"><h4>Checkoff</h4>
<ul>
	<li>Show TA that you have finished the above exercises.</li>
</ul>
</div>

<h3 id="exercise-2-how-many-documents-does-each-word-appear-in">Exercise 2: How many documents does each word appear in?</h3>

<p>Earlier, we used the <code>—END.OF.DOCUMENT—</code> token to split a text file into multiple documents. The sample files included in this lab are also split into documents. For example, <code>billOfRights.txt</code> is split into 10 documents (one for each amendment). For this exercise we want to count how many documents each word appears in. For example, <code>"Amendment"</code> should appear in all 10 documents of <code>billOfRights.txt</code>.</p>

<p>Open <code>perWordDocumentCount.py</code>. It currently contains code that will execute the same functionality as <code>wordCount.py</code>. Modify it to count the number of documents containing each word rather than the number of times each word occurs in the input and to sort that output in alphabetical order.</p>

<p>To help you with understanding the code, we have added some comments, but you will also need to take a look at the list of Spark <a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations">transformations</a> for a more detailed explanation of the methods that can be used in Spark. There are methods that you can use to help sort an output or remove duplicate items. To help with distinguishing when a word appears in a document, you will want to make use of the document ID as well – this is mentioned in the comments of <code>flatMapFunc</code>. Just because we gave you an outline doesn't mean you need to stick to it, feel free to add/remove transformations as you see fit. You're also encouraged to rename functions to more useful titles.</p>

<p>You can test <code>perWordDocumentCount.py</code> (with results in <code>spark-wc-out-perWordDocumentCount/part-00000</code>) with the following command:</p>

<div><pre>$ spark-submit perWordDocumentCount.py seqFiles/billOfRights.txt.seq</pre></div>

<p>You should also try it on the other sequence files you have to look for some
interesting results.</p>

<div class="checkoff"><h4>Checkoff</h4>
<ul>
	<li>Explain your modifications to <code>perWordDocumentCount.py</code> to your TA.</li>
	<li>Show your output from <code>billOfRights</code> to the TA. In particular, what values did you get for "Amendment", "the", and "arms"? Do these values make sense? You can confirm your results by looking through the <code>billOfRights.txt</code> file.</li>
</ul>
</div>

<h3 id="exercise-3-full-text-index-creation">Exercise 3: Full Text Index Creation</h3>

<p>Next, for each word and document in which that word appears at least once, we want to generate a list of index into the document for EACH appearance of the word, where an index is defined as the number of words since the beginning of the document (with the first word being index 0). Also make sure the output is sorted alphabetically by the word. Your output should have lines that look like the following (minor line formatting details don't matter):</p>

<div><pre>(word1  document1-id, word# word# ...)
(word1  document2-id, word# word# ...)
. . .
(word2  document1-id, word# word# ...)
(word2  document3-id, word# word# ...)
. . .</pre></div>

<p>Notice that there will be a line of output for EACH document in which that word
appears and EACH word and document pair should only have ONE list of indices.
Remember that you need to also keep track of the document ID as well.</p>

<p>For example, given a document with the text <code>With great power comes great responsibility</code>, the word <code>With</code> appears at index 0 while the word <code>great</code> appears at index 1 and 4, and the output would look like:</p>

<div><pre>('comes doc_somerandomnumbers', 3)
('great doc_somerandomnumbers', 1 4)
('power doc_somerandomnumbers', 2)
('responsibility doc_somerandomnumbers', 5)
('With doc_somerandomnumbers', 0)</pre></div>

<p>The file you should edit to do this task is <code>createIndices.py</code>. For this exercise, you may not need all the functions we have provided. If a function is not used, feel free to remove the method that is trying to call it. Make sure your output for this is sorted as well (just like in the previous exercise).</p>

<p>You can test by running the script with <code>spark-submit</code>:</p>

<div><pre>$ spark-submit createIndices.py seqFiles/billOfRights.txt.seq</pre></div>

<p>The results are stored in <code>spark-wc-out-createIndices/part-00000</code>. The output from running this will be a large file. In order to more easily look at its contents, you can use the commands <code>cat</code>, <code>head</code>, <code>more</code>, and <code>grep</code>:</p>

<div><pre>$ head -25 OUTPUTFILE       # view the first 25 lines of output
$ cat OUTPUTFILE | more     # scroll through output one screen at a time (use Space)
$ cat OUTPUTFILE | grep the # output only lines containing 'the' (case-sensitive)</pre></div>

<p>Make sure to verify your output. Open <code>billOfRights.txt</code> and pick a few words. Manually count a few of their word indices and make sure they all appear in your output file.</p>

<div class="checkoff"><h4>Checkoff</h4>
<ul>
	<li>Explain your code in <code>createIndices.py</code> to your TA. Next, run:
	<div><pre>$ spark-submit createIndices.py seqFiles/complete-works-mark-twain.txt.seq</pre></div></li>
	<li>Show your TA the first page of your output for the word "Mark" in <code>complete-works-mark-twain.txt.seq</code> to verify correct output. You can do this by running:
	<div><pre>$ cat spark-wc-out-createIndices/part-00000 | grep Mark | less</pre></div></li>
</ul>
</div>

<h3 id="exercise-4-whats-the-most-popular-word">Exercise 4: What's the most popular word?</h3>

<p>Use Spark to determine what the most popular non-article word is in the Bill of Rights. (Articles are the words "a", "an", and "the", so ignore those) We have copied over the code from <code>wordCount.py</code> into a new script <code>mostPopular.py</code> since it is a good starting point.</p>

<p><em>Hint:</em> After the <code>reduceByKey</code> operation has been run, you can still apply additional map operations to the data. Looking at the arguments for <code>sortByKey</code> may save you a lot of scrolling as well.</p>

<p>To test your code, run:</p>

<div><pre>$ spark-submit mostPopular.py seqFiles/billOfRights.txt.seq</pre></div>

<p>The results are stored in <code>spark-wc-out-mostPopular/part-00000</code>. As a fun exercise, try doing this on the book you downloaded in Exercise 0!</p>

<div class="checkoff"><h4>Checkoff</h4>
<ul>
	<li>Explain your code to the TA and what the most popular non-article word is.</li>
</ul>
</div>

<footer>
<hr style="clear: both;"/>
<div style="float:left">
<address>
Schwertfeger, S&ouml;ren &lt;<code>soerensch</code> AT <code>shanghaitech.edu.cn</code>&gt;
</address>
<address>
Chundong Wang &lt;<code>wangchd</code> AT <code>shanghaitech.edu.cn</code>&gt;
</address>
Last modified: <time datetime="2020-05-31">2020-05-31</time>
</div>

</footer>
</body>
</html>
